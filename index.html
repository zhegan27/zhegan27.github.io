<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="Ph.D. Candidate, Department of Electrical and Computer Engineering, 
	 Duke University" />
	<meta name="keywords" content="Zhe Gan, Deep Learning, Sigmoid Belief Networks, Duke University, Peking University" />
	<meta name="Zhe Gan" content="Research" />
	<link rel="stylesheet" type="text/css" href="Zhe.css" title="Basic Profile" media="all" />
	<title>Zhe Gan</title>
</head>

<body>


	<div id="sidebar">
		<a href="index.html"><img src="images/Zhe_new.jpg"  height="180" alt="Sample logotype" /></a>
		<h1><a style="text-decoration: none" href="index.html">Zhe Gan</a></h1>
		<!-- <p class="slogan">everyone has a story to tell</p> -->
		
		<ul>
			<!--<li><a href="#">Page one</a><br />The front page...</li>-->
			<li><a href="Paper.html">Publications</a></li>
			<li><a href="https://scholar.google.com/citations?user=E64XWyMAAAAJ&hl=en">Google Scholar</a></li>
			<li><a href="https://github.com/zhegan27">GitHub</a></li>
			<li><a href="https://www.linkedin.com/pub/zhe-gan/78/29a/a22">LinkedIn</a></li>
			<li><a href="CV_ZheGan.pdf">CV</a></li>
			<p>
			<font size="2">Dept. of Electrical and Computer Engineering <br>
			Duke University <br>
			Durham, NC 27708<br>
			Email: zhe.gan@duke.edu <br></font>
		</ul>
	</div>
	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35321140-3', â€˜zhegan.github.io');
  ga('send', 'pageview');

</script>
	
	<!--style="font-family: Calibri; color: blue; text-decoration: underline;"-->

	<div id="content">
		<!--<h2>What Starts Here Changes The World!</h2>-->
		<p>
		<p>
		<br>
		
		<p>I am a 5th year Ph.D. student at  <a style="color: #CC5500;" href="http://www.duke.edu/">
		Duke University</a>. I received my Master's and B.Sc.  
		from <a style="color: #CC5500;" href="http://www.pku.edu.cn/">Peking University</a> in 2013 and 2010, respectively. 
		My Ph.D. advisor is <a style="color: #CC5500;" href="http://people.ee.duke.edu/~lcarin">Lawrence Carin</a>. I can be reached at zhe.gan@duke.edu.
		
		<p>I work on deep learning, including generative models and its applications in vision and language intelligence. 

		<p>My PhD research can be summarized as follows (including collaboration with others):
		
		<ul>
		<li>
		<font><strong>Deep Generative Models</strong></font>:
			<ul>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <li> <font><strong>GAN</strong></font>: Triangle GAN [<a style=" color: blue;" href="https://arxiv.org/pdf/1709.06548.pdf">NIPS 2017</a>], textGAN [<a style=" color: blue;" href="https://arxiv.org/pdf/1706.03850.pdf">ICML 2017</a>]
			</li>

			<li> <font><strong>VAE</strong></font>: Adversarial Symmetric VAE [<a style=" color: blue;" href="https://arxiv.org/pdf/1711.04915.pdf">NIPS 2017</a>], Stein VAE [<a style=" color: blue;" href="https://arxiv.org/pdf/1704.05155.pdf">NIPS 2017</a>], VAE for semi-supervised learning [<a style=" color: blue;" href="https://arxiv.org/pdf/1609.08976.pdf">NIPS 2016</a>]
			</li>

			<li> <font><strong>SBN</strong></font>: Bayesian inference of SBN [<a style=" color: blue;" href="http://zhegan27.github.io/Papers/DeepSBN_AISTATS2015.pdf">AISTATS 2015</a>], SBN for topic modeling (PFA) [<a style=" color: blue;" href="http://zhegan27.github.io/Papers/DeepPFA_ICML2015.pdf">ICML 2015</a>, <a style=" color: blue;" href="http://zhegan27.github.io/Papers/DPFM_NIPS2015.pdf">NIPS 2015</a>] and sequence modeling [<a style=" color: blue;" href="https://arxiv.org/pdf/1509.07087.pdf">NIPS 2015</a>, <a style=" color: blue;" href="https://arxiv.org/pdf/1605.06715.pdf">ICML 2016</a>]
			</li>
			</ul>
		</li>
		
		<li>
		<font><strong>Vision and Language</strong></font>: image captioning [<a style=" color: blue;" href="https://arxiv.org/pdf/1611.08002v2.pdf">SCN, CVPR 2017</a>, <a style=" color: blue;" href="http://zhegan27.github.io/Papers/StyleNet_CVPR2017.pdf">StyleNet, CVPR 2017</a>], video captioning [<a style=" color: blue;" href="https://arxiv.org/pdf/1611.07837.pdf">AAAI 2018</a>] 
		</li>

		<li>
		<font><strong>NLP</strong></font>: Deconvolutional paragraph2vec [<a style=" color: blue;" href="https://arxiv.org/pdf/1708.04729.pdf">NIPS 2017</a>], CNN-based generic sent2vec [<a style=" color: blue;" href="https://arxiv.org/pdf/1611.07897.pdf">EMNLP 2017</a>], character-level deep conflation [<a style=" color: blue;" href="https://arxiv.org/pdf/1702.02640.pdf">ICASSP 2017</a>]
		</li>
		
		<li>
		<font><strong>SG-MCMC methods</strong></font>: SGMGT [<a style=" color: blue;" href="https://arxiv.org/pdf/1706.01498.pdf">ICML 2017</a>], Santa [<a style=" color: blue;" href="https://arxiv.org/pdf/1512.07962.pdf">AISTATS 2016</a>], pSGLD for shape classification [<a style=" color: blue;" href="http://zhegan27.github.io/Papers/dbnn_shape_cvpr.pdf">CVPR 2016</a>], pSGLD for NLP [<a style=" color: blue;" href="https://arxiv.org/pdf/1611.08034.pdf">ACL 2017</a>]
		</li>
		</ul>
		
		<p>
		<br/>
		
		<h3>Research Highlights:  </h3>
		<ul>

		<p> 
		<li>
		[2017/09] 4 papers got accepted to NIPS 2017; three of them are on deep generative models, including VAE and GAN variants; the other one is on deconvolutional paragraph representation learning. The acceptance ratio of NIPS 2017 is 678/3240= 20.93%.
		</li>

		<p> 
		<li>
		[2017/07] Our <a style=" color: blue;" href="https://arxiv.org/pdf/1611.07897.pdf">CNN_sent2vec</a> paper got accepted to EMNLP 2017 as an oral presentation.
		</li>

		<p> 
		<li>
		[2017/05] I got two papers accepted to ICML this year. One proposes a new GAN model for text generation that handles the discrete nature of text inputs and uses adversarial feature matching, based on our NIPS workshop paper. The other proposes a new SG-MCMC algorithm. These are joint work with <a style=" color: blue;" href="http://people.duke.edu/~yz196/">Yizhe</a>.
		</li>

		<p> 
		<li>
		[2017/04] Our paper on "<a style=" color: blue;" href="https://arxiv.org/pdf/1611.08034.pdf">Bayesian RNN using SG-MCMC</a>" is accepted by ACL 2017. 
		</li>

		<p> 
		<li>
		[2017/03] Two papers on image captioning are accepted by CVPR 2017. One proposes semantic compositional network for visual captioning, and the other proposes StyleNet that can generate stylized captions. 
		</li>

		<p> 
		<li>
		[2017/02] I will stay in MSR Redmond this summer again as a research intern, working in the <a style=" color: blue;" href="https://www.microsoft.com/en-us/research/group/dltc/">deep learning group</a>. 
		</li>

		<p> 
		<li>
		[2016/12] Our NIPS workshop paper "<a style=" color: blue;" href="http://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf">Generating text via Adversarial Training</a>" made some initial progress on training a generative adversarial network for generating realistic sentences. 
		</li>

		<p> 
		<li>
		[2016/11] Our AAAI 2017 paper "<a style=" color: blue;" href="https://arxiv.org/pdf/1611.04920v1.pdf">Unsupervised Learning with Truncated Gaussian Graphical Models</a>" proposes a new RBM variant that is closely related to ReLU-based neural networks. 
		</li>

		<p> 
		<li>
		[2016/09] The camera-ready version of our NIPS 2016 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/Yunchen_nips_2016.pdf">Variational Autoencoder for Deep Learning of Images, Labels and Captions</a>" is online now.
		</li>

		<p> 
		<li>
		[2016/05] Our ICML 2016 paper "<a style=" color: blue;" href="http://zhegan27.github.io/Papers/fctsbn_icml2016.pdf">Factored Temporal Sigmoid Belief Network</a>" developed a deep conditional generative model that can be used to simultaneously learn the temporal dependencies of multiple sequences. The model can also be utilized for semi-supervised sequence classification.
		</li>

		<p> 
		<li>
		[2016/05] We got one paper accepted by CVPR this year. The paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/dbnn_shape_cvpr.pdf">SG-MCMC for Shape Classification</a>" utilized SG-MCMC to train deep neural networks for the task of shape classification.
		</li>

		<p> 
		<li>
		[2016/02] Our AISTATS 2016 paper "<a style=" color: blue;" href="https://arxiv.org/pdf/1512.07962.pdf">Santa</a>" developed an optimization algorithm that bridges the gap between stochastic gradient MCMC and stochastic optimization.
		</li>

		
		<p class="credits">&copy; November 2017 Zhe Gan<br />
		</ul>
	</div>
</body>
</html>
