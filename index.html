<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="Senior Researcher, Microsoft Cloud and AI" />
	<meta name="keywords" content="Zhe Gan, Deep Learning, Machine Learning, Natural Language Processing, Microsoft, Duke University, Peking University" />
	<meta name="Zhe Gan" content="Research" />
	<link rel="stylesheet" type="text/css" href="Zhe.css" title="Basic Profile" media="all" />
	<title>Zhe Gan</title>
</head>

<body>


	<div id="sidebar">
		<a href="index.html"><img src="images/Zhe_new.jpg"  height="180" alt="Sample logotype" /></a>
		<h1><a style="text-decoration: none" href="index.html">Zhe Gan</a></h1>
		<!-- <p class="slogan">everyone has a story to tell</p> -->
		
		<ul>
			<!--<li><a href="#">Page one</a><br />The front page...</li>-->
			<li><a href="Paper.html">Publications</a></li>
			<li><a href="https://scholar.google.com/citations?user=E64XWyMAAAAJ&hl=en">Google Scholar</a></li>
			<li><a href="https://github.com/zhegan27">GitHub</a></li>
			<li><a href="https://www.linkedin.com/pub/zhe-gan/78/29a/a22">LinkedIn</a></li>
			<li><a href="CV_Zhe.pdf">CV</a></li>
			<p>
			<font size="2">Senior Researcher<br>
			Microsoft Cloud and AI<br>
			Redmond, WA 98052<br>
			Email: zhe.gan@microsoft.com <br></font>
		</ul>
	</div>
	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35321140-3', â€˜zhegan.github.io');
  ga('send', 'pageview');

</script>
	
	<!--style="font-family: Calibri; color: blue; text-decoration: underline;"-->

	<div id="content">
		<!--<h2>What Starts Here Changes The World!</h2>-->
		<p>
		<p>
		<br>
		
		<p> I am a Senior Researcher at <a style="color: #CC5500;" href="https://multimodalai.azurewebsites.net/">Microsoft Dynamics 365 AI Research</a>, primarily working on Vision-and-Language Representation Learning, Generative Pre-training, and Adversarial Machine Learning. I also have broad interests on other machine learning topics. I received my Ph.D. degree from <a style="color: #CC5500;" href="http://www.duke.edu/">Duke University</a> in Spring 2018. Before that, I received my Master's and B.Sc. from <a style="color: #CC5500;" href="http://www.pku.edu.cn/">Peking University</a> in 2013 and 2010, respectively. My Ph.D. advisor is <a style="color: #CC5500;" href="http://people.ee.duke.edu/~lcarin">Lawrence Carin</a>. I can be reached at zhe.gan@microsoft.com.


		<p> I am serving (or, has served) as an Area Chair for <a style="color: #CC5500;" href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a style="color: #CC5500;" href="https://2021.aclweb.org/">ACL 2021</a>, <a style="color: #CC5500;" href="https://iclr.cc/">ICLR 2021</a> and <a style="color: #CC5500;" href="https://nips.cc/Conferences/2020">NeurIPS 2020/2019</a>, and a Senior Program Committee (SPC) member for <a style="color: #CC5500;" href="https://aaai.org/Conferences/AAAI/aaai.php">AAAI 2021/2020</a>, and received <a style="color: #CC5500;" href="https://aaai.org/Awards/conference.php">AAAI-20 Outstanding SPC Award</a>. 
		
		<p>
		<br/>
		
		<h3>Research Highlights:  </h3>
		<ul>

		<p> 
		<li>
		[2021/03] Two papers accepted by CVPR 2021. Topics include (i) ClipBERT for video-and-language learning, and (ii) enhancing contrastive knowledge distillation with Wasserstein learning.
		</li>

		<p> 
		<li>
		[2021/02] We will host a tutorial at CVPR 2021: <a style="color: #CC5500;" href="https://vqa2vln-tutorial.github.io/">From VQA to VLN: Recent Advances in Vision-and-Language Research</a>. This year, we decide to extend our half-day event to a full one with enriched contents. Organizers include Peter Anderson, Yoav Artzi, Xiaodong He, Linjie Li, Jingjing Liu, Xin (Eric) Wang, Qi Wu, Luowei Zhou, and me.   
		</li>

		<p> 
		<li>
		[2021/01] Two papers accepted by ICLR 2021. Topics include using information-theoretic tools for (i) improved robustness of language models (BERT and RoBERTa) and (ii) zero-shot voice style transfer.
		</li>

		<p> 
		<li>
		[2021/01] Our <a style="color: #CC5500;" href="https://arxiv.org/pdf/1910.03230.pdf">Meta Module Network</a> wins the <font color="#FF0000">Best Student Paper Honorable Mention</font> Award at WACV 2021.   
		</li>

		<p> 
		<li>
		[2020/09] Our <a style="color: #CC5500;" href="https://arxiv.org/pdf/2006.06195.pdf">VILLA</a> paper got accepted to NeurIPS 2020 as a Spotlight paper with review scores 8887. It is the first known effort that studies large-scale adversarial training for vision-and-langauge representation learning in both pre-training and finetuning stages.   
		</li>

		<p> 
		<li>
		[2020/09] 7 long papers accepted by EMNLP 2020: (i) 6 of them accepted to the main conference, and (ii) 1 of them accepted to Findings of EMNLP 2020. Topics include: (i) Large-scale LM compression; (ii) Sentence embedding pre-training; (iii) Video+language pre-training; (iv) Constrained text generation via pre-training; (v) Summarization; (vi) Multi-hop reasoning for QA; and (vii) text style transfer.
		</li>

		<p> 
		<li>
		[2020/09] We achieve #1 on the <a style=" color: #CC5500;" href="https://sites.research.google/xtreme">XTREME</a> and <a style=" color: #CC5500;" href="https://microsoft.github.io/XGLUE/">XGLUE</a> leaderboards for cross-lingual language understanding. Welcome to check our <a style=" color: #CC5500;" href="https://arxiv.org/pdf/2009.05166.pdf">FILTER</a> paper. 
		</li>

		<p> 
		<li>
		[2020/09] 2 papers accepted by ACCV 2020. Topics include: (i) face image editing; and (ii) unsupervised domain adaptation.
		</li>

		<p> 
		<li>
		[2020/08] Will serve as an Area Chair for ICLR 2021, and a SPC member (i.e., Meta-Reviewer) for AAAI 2021.  
		</li>

		<p> 
		<li>
		[2020/07] Two papers got accepted to ECCV 2020. (1) UNITER: a state-of-the-art pre-trained Vision+Language (V+L) model; (2) VALUE (ECCV Spotlight): the first work on probing pre-trained V+L models.  
		</li>

		<p> 
		<li>
		[2020/06] Two papers got accepted to ICML 2020. (i) CLUB: a novel upper bound of mutual information that is deeply connected with contrastive learning. (ii) GOT: a graph optimal transport framework for cross-domain alignment that can be used for V+L and NLP problems, such as VQA and NMT.   
		</li>

		<p> 
		<li>
		[2020/06] At this year's CVPR, we will give a tutorial on "Recent Advances in Vision-and-Language Research", covering the recent popular multi-modal pre-training methods and other topics. More details are provided in the website <a style="color: #CC5500;" href="https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/">here</a>.  
		</li>

		<p> 
		<li>
		[2020/04] Two CVPR and three ACL papers got accepted, respectively. CVPR papers cover topics including: (i) high-resolution image synthesis from salient object layout, and (ii) a new dataset for video-and-language understanding. ACL papers cover topics include: (i) text summarization based on discourse units, (ii) BERT for text generation, and (iii) text generation that models the distant future.    
		</li>

		<p> 
		<li>
		[2020/03] Will serve as an Area Chair for <a style="color: #CC5500;" href="https://nips.cc/Conferences/2020">NeurIPS 2020</a>.  
		</li>

		<p> 
		<li>
		[2020/01] I received AAAI-20 Outstanding SPC Award.
		</li>

		<p> 
		<li>
		[2019/09] Our new work <a style="color: #CC5500;" href="https://arxiv.org/pdf/1909.11740.pdf">UNITER</a> achieves SOTA on 6 Vision-and-Language tasks across 9 datasets (VQA, VCR, NLVR, Img-Txt Retrieval, Visual Entailment, Referring Expression).
		</li>

		<p> 
		<li>
		[2019/09] Our latest Adversarial Training model has beaten Facebook's RoBERTa on <a style="color: #CC5500;" href="https://gluebenchmark.com/leaderboard/">GLUE benchmark</a>. Paper is available <a style="color: #CC5500;" href="https://arxiv.org/pdf/1909.11764.pdf">here</a>.
		</li>

		<p> 
		<li>
		[2019/08] 4 papers got accepted to EMNLP. Topics include (i) BERT model compression, (ii) domain adaptation for MRC, (iii) domain adaptation for text style transfer, and (iv) image caption evaluation. 
		</li>
		
		<p class="credits">&copy; March 2021 Zhe Gan<br />
		</ul>
	</div>
</body>
</html>
