<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="Ph.D. Candidate, Department of Electrical and Computer Engineering, 
	 Duke University" />
	<meta name="keywords" content="Zhe Gan, Deep Learning, Sigmoid Belief Networks, Duke University, Peking University" />
	<meta name="Zhe Gan" content="Research" />
	<link rel="stylesheet" type="text/css" href="Zhe.css" title="Basic Profile" media="all" />
	<title>Zhe Gan</title>
</head>

<body>


	<div id="sidebar">
		<a href="index.html"><img src="images/Zhe_new.jpg"  height="180" alt="Sample logotype" /></a>
		<h1><a style="text-decoration: none" href="index.html">Zhe Gan</a></h1>
		<!-- <p class="slogan">everyone has a story to tell</p> -->
		
		<ul>
			<!--<li><a href="#">Page one</a><br />The front page...</li>-->
			<li><a href="Paper.html">Publications</a></li>
			<li><a href="https://scholar.google.com/citations?user=E64XWyMAAAAJ&hl=en">Google Scholar</a></li>
			<li><a href="https://github.com/zhegan27">GitHub</a></li>
			<li><a href="https://www.linkedin.com/pub/zhe-gan/78/29a/a22">LinkedIn</a></li>
			<li><a href="CV_ZheGan.pdf">CV</a></li>
			<p>
			<font size="2">Dept. of Electrical and Computer Engineering <br>
			Duke University <br>
			Durham, NC 27708<br>
			Email: zhe.gan@duke.edu <br></font>
		</ul>
	</div>
	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35321140-3', â€˜zhegan.github.io');
  ga('send', 'pageview');

</script>
	
	<!--style="font-family: Calibri; color: blue; text-decoration: underline;"-->

	<div id="content">
		<!--<h2>What Starts Here Changes The World!</h2>-->
		<p>
		<p>
		<br>
		
		<p>I am a fourth year Ph.D. Candidate at  <a style="color: #CC5500;" href="http://www.duke.edu/">
		Duke University</a>. I received my Master's and B.Sc.  
		from <a style="color: #CC5500;" href="http://www.pku.edu.cn/">Peking University</a> in 2013 and 2010, respectively. 
		My Ph.D. advisor is <a style="color: #CC5500;" href="http://people.ee.duke.edu/~lcarin">Lawrence Carin</a>. I can be reached at zhe.gan@duke.edu.
		
		<p>I focus on designing efficient and scalable Bayesian inference algorithms for deep learning models with applications in natural language processing and computer vision. 
		<p>
		
		<br/>
		
		<h3>Research Highlights:  </h3>
		<ul>

		<p> 
		<li>
		[2017/04] Our paper on "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/bayesian_rnn.pdf">Bayesian RNN using SG-MCMC</a>" is accepted by ACL 2017. 
		</li>

		<p> 
		<li>
		[2017/03] Two papers on image captioning are accepted by CVPR 2017. One proposes semantic compositional network for visual captioning, and the other proposes StyleNet that can generate stylized captions. 
		</li>

		<p> 
		<li>
		[2017/02] I will stay in MSR Redmond this summer again as a research intern, working in the <a style=" color: blue;" href="https://www.microsoft.com/en-us/research/group/dltc/">deep learning group</a>. 
		</li>

		<p> 
		<li>
		[2016/12] Our NIPS workshop paper "<a style=" color: blue;" href="http://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf">Generating text via Adversarial Training</a>" made some initial progress on training a generative adversarial network for generating realistic sentences. 
		</li>

		<p> 
		<li>
		[2016/11] Our AAAI 2017 paper "<a style=" color: blue;" href="https://arxiv.org/pdf/1611.04920v1.pdf">Unsupervised Learning with Truncated Gaussian Graphical Models</a>" proposes a new RBM variant that is closely related to ReLU-based neural networks. 
		</li>

		<p> 
		<li>
		[2016/09] The camera-ready version of our NIPS 2016 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/Yunchen_nips_2016.pdf">Variational Autoencoder for Deep Learning of Images, Labels and Captions</a>" is online now.
		</li>

		<p> 
		<li>
		[2016/05] Our ICML 2016 paper "<a style=" color: blue;" href="http://zhegan27.github.io/Papers/fctsbn_icml2016.pdf">Factored Temporal Sigmoid Belief Network</a>" developed a deep conditional generative model that can be used to simultaneously learn the temporal dependencies of multiple sequences. The model can also be utilized for semi-supervised sequence classification.
		</li>

		<p> 
		<li>
		[2016/05] We got one paper accepted by CVPR this year. The paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/dbnn_shape_cvpr.pdf">SG-MCMC for Shape Classification</a>" utilized SG-MCMC to train deep neural networks for the task of shape classification.
		</li>

		<p> 
		<li>
		[2016/02] Our AISTATS 2016 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/Santa_aistats16.pdf">Santa</a>" developed an optimization algorithm that bridges the gap between stochastic gradient MCMCand stochastic optimization.
		</li>

		<p> 
		<li>
		[2015/10] We submitted two papers to AISTATS 2016.
		</li>

		<p>
		<li> [2015/10] Our NIPS 2015 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/dpfa_nips.pdf">Deep Poisson Factor Modeling</a>" propose a new deep architecture for topic modeling, based on Poisson Factor
Analysis (PFA) modules. Rather than using logistic functions to characterize the probability that a latent binary unit is on, we employ a Bernoulli-Poisson link, which allows PFA modules to be used repeatedly in the deep architecture.
		</li>


		<p>
		<li> [2015/10] Our NIPS 2015 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/TSBN_NIPS2015.pdf">Temporal Sigmoid Belief Network</a>" developed a deep dynamic generative model to learn sequential dependencies
in time-series data. The temporal sigmoid belief networks (TSBNs) are defined as a sequential stack of sigmoid belief networks (SBNs).
		</li>
	
		
		<p>  
		<li> [2015/06] We submitted two papers to NIPS 2015. </li>
		
		<p>
		<li> [2015/05] Our ICML 2015 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/DeepPFA_ICML2015.pdf">Deep Poisson Factor Analysis</a>" introduced a new framework for topic modeling, based on deep graphical models, where interactions between topics are inferred through deep latent binary hierarchies.
		</li>
		
		<p>
		<li> [2015/02] Our AISTATS 2015 paper "<a style=" color: blue;" href="http://people.ee.duke.edu/~lcarin/dsbn_aistats2015.pdf">Deep Sigmoid Belief Networks</a>" developed deep directed generative models by stacking sigmoid belief networks.
		</li>
		
		<p class="credits">&copy; April 2017 Zhe Gan<br />
		</ul>
	</div>
</body>
</html>
